apiVersion: batch/v1
kind: CronJob
metadata:
  name: hafjet-mongo-backup
spec:
  schedule: "0 2 * * *" # daily at 02:00
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
            - name: mongodump
              image: mongo:7
              env:
                - name: MONGO_URI
                  value: mongodb://mongo:27017/hafjet-bukku
              command:
                - /bin/sh
                - -c
                - |
                  set -euo pipefail
                  TIMESTAMP=$(date +"%F_%H%M%S")
                  FILE="/backup/backup-${TIMESTAMP}.gz"
                  echo "Creating backup $FILE"
                  mongodump --uri="$MONGO_URI" --archive="$FILE" --gzip
            - name: uploader
              image: amazon/aws-cli:latest
              env:
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: hafjet-backup-secrets
                      key: aws_access_key_id
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: hafjet-backup-secrets
                      key: aws_secret_access_key
                - name: S3_BUCKET
                  valueFrom:
                    secretKeyRef:
                      name: hafjet-backup-secrets
                      key: s3_bucket
                - name: AWS_REGION
                  valueFrom:
                    secretKeyRef:
                      name: hafjet-backup-secrets
                      key: aws_region
                - name: ENCRYPTION_PASSPHRASE
                  valueFrom:
                    secretKeyRef:
                      name: hafjet-backup-secrets
                      key: backup_passphrase
              command:
                - /bin/sh
                - -c
                - |
                  set -euo pipefail
                  # Wait for a backup file to appear
                  for i in $(seq 1 60); do
                    if ls /backup/*.gz >/dev/null 2>&1; then break; fi
                    sleep 1
                  done
                  for f in /backup/*.gz; do
                    echo "Found $f"
                    if [ -n "${ENCRYPTION_PASSPHRASE:-}" ]; then
                      echo "Encrypting $f"
                      ENC="$f.enc"
                      # Ensure openssl exists; amazonlinux should have openssl
                      openssl enc -aes-256-cbc -pbkdf2 -salt -in "$f" -out "$ENC" -pass pass:"$ENCRYPTION_PASSPHRASE"
                      echo "Uploading $ENC to s3://$S3_BUCKET/"
                      aws --region "$AWS_REGION" s3 cp "$ENC" "s3://$S3_BUCKET/"
                      rm -f "$ENC" "$f"
                    else
                      echo "Uploading $f to s3://$S3_BUCKET/"
                      aws --region "$AWS_REGION" s3 cp "$f" "s3://$S3_BUCKET/"
                      rm -f "$f"
                    fi
                  done
          volumes:
            - name: backup-pvc
              persistentVolumeClaim:
                claimName: hafjet-backup-pvc
          volumeMounts:
            - name: backup-pvc
              mountPath: /backup
          # shared volume mounts for each container
        metadata: {}
